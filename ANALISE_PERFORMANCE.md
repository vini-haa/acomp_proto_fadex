# üîç An√°lise de Performance - Portal FADEX

**Data:** 24 de novembro de 2025
**Objetivo:** Identificar e documentar gargalos de performance da aplica√ß√£o

---

## üìä Resumo Executivo

A aplica√ß√£o est√° apresentando **lentid√£o significativa** com tempos de resposta entre **5-8 segundos** para queries principais. O carregamento inicial da p√°gina dashboard demora **~17 segundos**.

### Principais Problemas Identificados:

1. ‚ö†Ô∏è **CTE Base Extremamente Complexo** (140 linhas, 4 CTEs aninhados)
2. ‚ö†Ô∏è **Falta de √çndices no Banco de Dados**
3. ‚ö†Ô∏è **Carregamento de 50.000 registros de uma vez** (exporta√ß√£o)
4. ‚ö†Ô∏è **M√∫ltiplas Queries Pesadas em Paralelo** (4 queries com ~7s cada)
5. ‚ö†Ô∏è **JOINs Desnecess√°rios** (8 LEFT JOINs por query)
6. ‚ö†Ô∏è **Cache Ineficaz**

---

## üö® Problemas Cr√≠ticos

### 1. CTE Base Complexo (CR√çTICO)

**Arquivo:** `lib/queries/base-cte.ts`

**Problema:**

```sql
-- 4 CTEs aninhados executados em TODAS as queries:
WITH ProtocolosAtuaisNoSetor AS (...)  -- Subquery com EXISTS
, MovimentacoesFinanceiro AS (...)      -- GROUP BY + EXISTS subquery
, SetorAtual AS (...)                   -- ROW_NUMBER() OVER
, vw_ProtocolosFinanceiro AS (...)      -- 6 CASE WHENs repetidos
```

**Impacto:**

- Executado em **TODAS** as queries da aplica√ß√£o
- 140 linhas de SQL complexo recalculado sempre
- C√°lculos de `dias_no_financeiro` e `faixa_tempo` repetidos 6 vezes
- ROW_NUMBER() OVER √© custoso

**Tempo estimado:** +3-5 segundos por query

**Evid√™ncia nos logs:**

```
GET /api/kpis?periodo=all 200 in 7249ms
GET /api/analytics/distribuicao 200 in 7280ms
GET /api/analytics/temporal?periodo=30d 200 in 6889ms
GET /api/analytics/comparativo 200 in 6381ms
```

---

### 2. Falta de √çndices (CR√çTICO)

**Problema:**
Nenhum √≠ndice foi criado nas colunas mais consultadas:

**√çndices faltantes:**

```sql
-- Tabela: scd_movimentacao
CREATE INDEX idx_movimentacao_codsetordestino ON scd_movimentacao(codsetordestino)
  WHERE codsetordestino = 48;

CREATE INDEX idx_movimentacao_RegAtual ON scd_movimentacao(RegAtual)
  WHERE RegAtual = 1;

CREATE INDEX idx_movimentacao_codprot ON scd_movimentacao(codprot);

CREATE INDEX idx_movimentacao_data ON scd_movimentacao(data);

CREATE INDEX idx_movimentacao_composite
  ON scd_movimentacao(codsetordestino, RegAtual, codprot, data)
  WHERE codsetordestino = 48 AND RegAtual = 1;

-- Tabela: documento
CREATE INDEX idx_documento_codigo ON documento(codigo) WHERE deletado IS NULL;
CREATE INDEX idx_documento_numconv ON documento(numconv) WHERE deletado IS NULL;
CREATE INDEX idx_documento_assunto ON documento(assunto) WHERE deletado IS NULL;

-- Tabela: convenio
CREATE INDEX idx_convenio_numconv ON convenio(numconv) WHERE deletado IS NULL;
```

**Impacto:**

- SQL Server faz **Table Scan** em vez de **Index Seek**
- Filtros `WHERE codsetordestino = 48` escaneiam toda a tabela
- JOINs sem √≠ndices s√£o extremamente lentos

**Tempo estimado:** +4-6 segundos por query

---

### 3. Carregamento de 50.000 Registros (ALTO)

**Evid√™ncia nos logs:**

```
GET /api/protocolos?page=1&pageSize=50000 200 in 8545ms
```

**Problema:**

- Algu√©m est√° chamando a API com `pageSize=50000`
- Provavelmente para exporta√ß√£o de dados
- Carrega 50 mil registros + executa CTE base complexo
- Cada registro faz 8 LEFT JOINs

**Solu√ß√£o necess√°ria:**

- Implementar endpoint dedicado para exporta√ß√£o
- Usar streaming para grandes volumes
- Limitar pageSize m√°ximo (ex: 1000)

---

### 4. M√∫ltiplas Queries em Paralelo (M√âDIO)

**Evid√™ncia:**

```
P√°gina inicial carrega 4 queries simultaneamente:
GET /api/kpis?periodo=all          7249ms
GET /api/analytics/distribuicao    7280ms
GET /api/analytics/temporal        6889ms
GET /api/analytics/comparativo     6381ms
```

**Problema:**

- 4 queries pesadas executadas ao mesmo tempo
- Cada uma executa o CTE base completo
- Competem por recursos do pool de conex√µes (max: 10)
- Primeira renderiza√ß√£o demora 17+ segundos

**Solu√ß√£o:**

- Implementar cache server-side
- Carregar dados cr√≠ticos primeiro (KPIs), depois gr√°ficos
- Considerar Server-Sent Events (SSE) para streaming progressivo

---

### 5. JOINs Desnecess√°rios (M√âDIO)

**Arquivo:** `lib/queries/protocolos.ts:56-88`

**Problema:**

```sql
-- 8 LEFT JOINs em TODAS as queries de listagem:
LEFT JOIN documento d ON ...
LEFT JOIN convenio c ON ...
LEFT JOIN conv_cc ccc ON ...
LEFT JOIN cc ON ...
LEFT JOIN setor so ON ...
LEFT JOIN setor sd ON ...
```

**Impacto:**

- Cada protocolo faz 8 JOINs (sem √≠ndices)
- Para 50.000 registros = 400.000 opera√ß√µes de JOIN
- Muitos dados podem n√£o ser necess√°rios na listagem

**Solu√ß√£o:**

- Criar query simplificada para listagem (apenas dados essenciais)
- Query detalhada apenas para visualiza√ß√£o de protocolo individual
- Considerar desnormaliza√ß√£o de dados cr√≠ticos

---

### 6. Cache Ineficaz (M√âDIO)

**Configura√ß√£o atual:**

```typescript
// app/api/protocolos/route.ts:83
export const revalidate = 60; // 1 minuto
```

**Problema:**

- Cache configurado mas n√£o parece estar funcionando
- Logs mostram "‚úÖ Conex√£o com SQL Server estabelecida" m√∫ltiplas vezes
- Dados s√£o recalculados a cada requisi√ß√£o

**Solu√ß√£o:**

- Implementar cache no Redis/Memcached
- Cache de KPIs por 5 minutos
- Cache de queries anal√≠ticas por 10-15 minutos
- Invalida√ß√£o de cache quando h√° novas movimenta√ß√µes

---

## üìà An√°lise Detalhada dos Logs

### Tempo de Resposta por Endpoint:

| Endpoint                             | Tempo        | Status     | Problema Principal             |
| ------------------------------------ | ------------ | ---------- | ------------------------------ |
| `GET /` (primeira renderiza√ß√£o)      | **17.352ms** | üî¥ CR√çTICO | Compila√ß√£o + 4 queries pesadas |
| `GET /api/kpis?periodo=all`          | **7.249ms**  | üî¥ CR√çTICO | CTE base + sem √≠ndices         |
| `GET /api/analytics/distribuicao`    | **7.280ms**  | üî¥ CR√çTICO | CTE base + sem √≠ndices         |
| `GET /api/analytics/temporal`        | **6.889ms**  | üî¥ CR√çTICO | CTE base + m√∫ltiplos CTEs      |
| `GET /api/analytics/comparativo`     | **6.381ms**  | üü° ALTO    | CTE base + GROUP BY            |
| `GET /api/protocolos?pageSize=50000` | **8.545ms**  | üî¥ CR√çTICO | 50k registros + 8 JOINs cada   |
| `GET /api/alertas`                   | **5.377ms**  | üü° ALTO    | CTE base                       |
| `GET /api/protocolos/[id]`           | **3.489ms**  | üü° M√âDIO   | CTE base + JOINs               |
| `GET /api/kpis?periodo=mes_atual`    | **614ms**    | üü¢ BOM     | Menos dados filtrados          |
| `GET /api/analytics/por-assunto`     | **2.660ms**  | üü¢ BOM     | Query simples                  |

### Padr√µes Identificados:

1. **Queries com CTE base:** 5-8 segundos
2. **Queries sem CTE base:** 1-3 segundos
3. **Queries com filtro de per√≠odo:** 600ms-2s (muito melhor!)
4. **Primeira renderiza√ß√£o:** 17+ segundos

---

## üéØ Plano de Otimiza√ß√£o

### Fase 1: Ganhos R√°pidos (70% de melhoria)

#### 1.1. Criar √çndices no Banco (PRIORIDADE M√ÅXIMA)

```sql
-- Tempo estimado: 5 minutos
-- Ganho: 4-6 segundos por query

-- √çndice principal para setor 48
CREATE INDEX idx_mov_setor48_regAtual
  ON scd_movimentacao(codsetordestino, RegAtual, codprot, data)
  WHERE codsetordestino = 48 AND Deletado IS NULL;

-- √çndices de suporte
CREATE INDEX idx_mov_codprot ON scd_movimentacao(codprot) WHERE Deletado IS NULL;
CREATE INDEX idx_mov_data ON scd_movimentacao(data);
CREATE INDEX idx_documento_codigo ON documento(codigo) WHERE deletado IS NULL;
CREATE INDEX idx_convenio_numconv ON convenio(numconv) WHERE deletado IS NULL;
```

**Resultado esperado:** 7s ‚Üí 2-3s

#### 1.2. Limitar pageSize M√°ximo

```typescript
// Tempo estimado: 2 minutos
// Ganho: Previne queries extremamente lentas

const pageSize = Math.min(filters.pageSize || 20, 1000); // M√°ximo 1000
```

#### 1.3. Implementar Cache Server-Side

```typescript
// Tempo estimado: 30 minutos
// Ganho: 5-7 segundos ap√≥s primeiro acesso

// Usar React Query com staleTime mais agressivo
const { data: kpis } = useKPIs(periodo, {
  staleTime: 5 * 60 * 1000, // 5 minutos
  cacheTime: 10 * 60 * 1000, // 10 minutos
});
```

---

### Fase 2: Otimiza√ß√£o Estrutural (20% adicional)

#### 2.1. Simplificar CTE Base

```sql
-- Dividir em 2 vers√µes:
-- 1. BASE_CTE_SIMPLE: Para listagens (apenas campos essenciais)
-- 2. BASE_CTE_FULL: Para detalhes e an√°lises

-- Remover c√°lculos repetidos de faixa_tempo
-- Calcular uma √∫nica vez, reutilizar
```

#### 2.2. Criar Queries Espec√≠ficas

```sql
-- Query otimizada para KPIs (sem JOINs desnecess√°rios)
-- Query otimizada para listagem (campos m√≠nimos)
-- Query completa apenas para detalhes
```

#### 2.3. Desnormalizar Dados Cr√≠ticos

```sql
-- Tabela auxiliar: protocolo_status_cache
-- Atualizada via trigger quando h√° movimenta√ß√µes
-- Evita recalcular dias_no_financeiro toda vez
```

---

### Fase 3: Arquitetura (10% adicional)

#### 3.1. Implementar Cache Distribu√≠do (Redis)

- Cache de KPIs: 5 minutos
- Cache de analytics: 15 minutos
- Invalida√ß√£o inteligente

#### 3.2. Background Jobs

- Pr√©-calcular m√©tricas a cada 5 minutos
- Armazenar em tabela de cache
- Dashboard consulta cache, n√£o recalcula

#### 3.3. Streaming para Exporta√ß√µes

```typescript
// Usar streaming para grandes volumes
export async function* streamProtocolos() {
  // Yield dados em chunks de 1000
}
```

---

## üìä Resultados Esperados

### Performance Atual:

- ‚è±Ô∏è Dashboard load: **17 segundos**
- ‚è±Ô∏è Queries principais: **5-8 segundos**
- ‚è±Ô∏è Exporta√ß√£o 50k: **8+ segundos**

### Ap√≥s Fase 1 (√çndices + Cache + Limite):

- ‚è±Ô∏è Dashboard load: **3-5 segundos** (70% melhoria) ‚úÖ
- ‚è±Ô∏è Queries principais: **1-2 segundos** (75% melhoria) ‚úÖ
- ‚è±Ô∏è Exporta√ß√£o: **Endpoint dedicado** ‚úÖ

### Ap√≥s Fase 2 (Otimiza√ß√£o Estrutural):

- ‚è±Ô∏è Dashboard load: **2-3 segundos** (82% melhoria) ‚úÖ
- ‚è±Ô∏è Queries principais: **500ms-1s** (87% melhoria) ‚úÖ

### Ap√≥s Fase 3 (Arquitetura):

- ‚è±Ô∏è Dashboard load: **<1 segundo** (95% melhoria) ‚úÖ
- ‚è±Ô∏è Queries principais: **100-300ms** (96% melhoria) ‚úÖ

---

## üîß Recomenda√ß√µes Imediatas

### Para Implementar HOJE:

1. **Criar √≠ndices no banco** (5 min, 60% ganho)

   ```bash
   # Executar script de √≠ndices
   ```

2. **Limitar pageSize** (2 min, previne problemas)

   ```typescript
   const pageSize = Math.min(filters.pageSize || 20, 1000);
   ```

3. **Aumentar staleTime do cache** (5 min, 20% ganho)
   ```typescript
   staleTime: 5 * 60 * 1000;
   ```

### Para Semana Que Vem:

4. Simplificar CTE base
5. Criar queries otimizadas
6. Implementar endpoint de exporta√ß√£o dedicado

### Para o Futuro (Expans√£o para outros setores):

7. Parametrizar setor (n√£o hard-code 48)
8. Implementar cache distribu√≠do (Redis)
9. Background jobs para pr√©-c√°lculo
10. Considerar materializa√ß√£o de views

---

## üìù Notas Sobre Expans√£o Futura

O usu√°rio mencionou:

> "iremos expandir para outros setores, assim como tamb√©m aumentaremos a an√°lise para a funda√ß√£o inteira"

### Considera√ß√µes para Expans√£o:

1. **Parametrizar setor:**
   - N√£o usar `codsetordestino = 48` hard-coded
   - Aceitar m√∫ltiplos setores como par√¢metro
   - Filtrar por array de setores

2. **Escala funda√ß√£o inteira:**
   - Volume de dados ser√° MUITO maior
   - √çndices s√£o ainda MAIS cr√≠ticos
   - Cache se torna obrigat√≥rio
   - Considerar particionamento de tabelas

3. **Performance cr√≠tica:**
   - Com mais dados, problemas atuais ser√£o amplificados
   - Otimiza√ß√µes da Fase 1-3 ser√£o ESSENCIAIS
   - Considerar read replicas para analytics

---

## üéØ Conclus√£o

A lentid√£o atual √© causada principalmente por:

1. **Falta de √≠ndices** ‚Üí 50% do problema
2. **CTE base complexo** ‚Üí 30% do problema
3. **Carregamento excessivo de dados** ‚Üí 15% do problema
4. **Cache ineficaz** ‚Üí 5% do problema

**Implementando apenas os √≠ndices, o ganho ser√° de 4-6 segundos por query.**

Com as otimiza√ß√µes da Fase 1, a aplica√ß√£o ficar√° **70% mais r√°pida** em menos de 1 hora de trabalho.

---

**Pr√≥ximos passos:**

1. ‚úÖ Criar script de √≠ndices
2. ‚úÖ Aplicar limites de pageSize
3. ‚úÖ Ajustar cache do React Query
4. üîÑ Testar e medir resultados
5. üîÑ Iterar conforme necess√°rio
